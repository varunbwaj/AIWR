{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import tensorflow as tf\n",
    "from helper_functions import *\n",
    "import pandas as pd\n",
    "# importTensorflow(memory=4090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>String</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Duck or goose liver recipes</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French delicacy made from liver</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury food items from France</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to cook liver in a luxurious way</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dishes using corn-fed duck liver</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 String      Class\n",
       "0           Duck or goose liver recipes  foie_gras\n",
       "1       French delicacy made from liver  foie_gras\n",
       "2         Luxury food items from France  foie_gras\n",
       "3  How to cook liver in a luxurious way  foie_gras\n",
       "4      Dishes using corn-fed duck liver  foie_gras"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"queries1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = os.listdir(\"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = set()\n",
    "counter = -1\n",
    "l = []\n",
    "for thing in df.Class:\n",
    "    if thing in d:\n",
    "      l.append(counter)\n",
    "    else:\n",
    "        counter += 1\n",
    "        d.add(thing)\n",
    "        l.append(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classEncode'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>String</th>\n",
       "      <th>Class</th>\n",
       "      <th>classEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Duck or goose liver recipes</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>French delicacy made from liver</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury food items from France</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to cook liver in a luxurious way</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dishes using corn-fed duck liver</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 String      Class  classEncode\n",
       "0           Duck or goose liver recipes  foie_gras            0\n",
       "1       French delicacy made from liver  foie_gras            0\n",
       "2         Luxury food items from France  foie_gras            0\n",
       "3  How to cook liver in a luxurious way  foie_gras            0\n",
       "4      Dishes using corn-fed duck liver  foie_gras            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>String</th>\n",
       "      <th>Class</th>\n",
       "      <th>classEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>Recipes using dough and tomatoes</td>\n",
       "      <td>pizza</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>How to make a dish with ground beef and cheese</td>\n",
       "      <td>nachos</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>Recipe for seafood with butter and white wine</td>\n",
       "      <td>scallops</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Making a spicy snack with a dough wrapper</td>\n",
       "      <td>samosa</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>How to prepare a dish with spaghetti and a me...</td>\n",
       "      <td>spaghetti_bolognese</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 String                Class  \\\n",
       "3896                   Recipes using dough and tomatoes                pizza   \n",
       "3933     How to make a dish with ground beef and cheese               nachos   \n",
       "2795      Recipe for seafood with butter and white wine             scallops   \n",
       "352           Making a spicy snack with a dough wrapper               samosa   \n",
       "1277   How to prepare a dish with spaghetti and a me...  spaghetti_bolognese   \n",
       "\n",
       "      classEncode  \n",
       "3896           79  \n",
       "3933           80  \n",
       "2795           57  \n",
       "352             7  \n",
       "1277           25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.String, df.classEncode, test_size=0.1, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4488, 499)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length = 25000\n",
    "max_length = [len(i.split()) for i in df.String]\n",
    "max_length = int(np.percentile(max_length, 95))\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "text_vector = tf.keras.layers.TextVectorization(max_tokens=vocab_length,\n",
    "                                                output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector.adapt(df.String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'with', 'a', 'and']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "embedding = tf.keras.layers.Embedding(input_dim = vocab_length,\n",
    "                                      input_length=max_length,\n",
    "                                      output_dim=1024,\n",
    "                                      mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_train = tf.one_hot(y_train, depth=101)\n",
    "one_hot_encoded_test = tf.one_hot(y_test, depth=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_one_hot = tf.data.Dataset.from_tensor_slices((X_train, one_hot_encoded_train)).shuffle(1000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "test_data_one_hot = tf.data.Dataset.from_tensor_slices((X_test, one_hot_encoded_test)).batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 12)                0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 12, 1024)          25600000  \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 12, 1024)          4724736   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 128)               443136    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 101)               13029     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30797925 (117.48 MB)\n",
      "Trainable params: 30797669 (117.48 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# conv1d\n",
    "inputs = tf.keras.layers.Input(shape=(1, ), dtype='string')\n",
    "x = text_vector(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, return_sequences=True))(x)\n",
    "x = tf.keras.layers.GRU(128)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(len(class_list), activation='softmax')(x)\n",
    "\n",
    "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch : 3e-3/(1+epoch)**(2))\n",
    "\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 30s 352ms/step - loss: 2.4011 - accuracy: 0.4514 - val_loss: 1.2423 - val_accuracy: 0.7969\n",
      "Epoch 2/5\n",
      "71/71 [==============================] - 23s 321ms/step - loss: 0.4398 - accuracy: 0.8734 - val_loss: 0.3751 - val_accuracy: 0.9297\n",
      "Epoch 3/5\n",
      "71/71 [==============================] - 23s 328ms/step - loss: 0.3234 - accuracy: 0.9000 - val_loss: 0.3826 - val_accuracy: 0.8984\n",
      "Epoch 4/5\n",
      "71/71 [==============================] - 24s 340ms/step - loss: 0.2320 - accuracy: 0.9245 - val_loss: 0.3000 - val_accuracy: 0.9219\n",
      "Epoch 5/5\n",
      "71/71 [==============================] - 25s 349ms/step - loss: 0.2158 - accuracy: 0.9356 - val_loss: 0.2610 - val_accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_one_hot,\n",
    "                    epochs=5,\n",
    "                    validation_data=(test_data_one_hot),\n",
    "                    validation_steps=int(0.25*len(test_data_one_hot)),\n",
    "                    steps_per_epoch=len(train_data_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 129ms/step - loss: 0.3576 - accuracy: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3576110601425171, 0.8957915902137756]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bidir_gru/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bidir_gru/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"bidir_gru/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([75])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(model.predict([\"recipes with Mustard and bread\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tacos'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tacos'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list[tf.argmax(model.predict([\"Dinner recipes with beef and jalapenos\"]), axis=1).numpy()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bruschetta'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.8837675350701403\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('queries1.csv')\n",
    "\n",
    "X = df['String']\n",
    "y = df['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that first transforms your data using TF-IDF and then fits it to a Naive Bayes classifier\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train your model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate your model using the testing data\n",
    "print(\"Model Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hot_dog']\n"
     ]
    }
   ],
   "source": [
    "# Your custom string\n",
    "custom_string = \"sausage and bread\"\n",
    "\n",
    "# Transform your string into a TF-IDF vector\n",
    "custom_string_transformed = model.named_steps['tfidfvectorizer'].transform([custom_string])\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.named_steps['multinomialnb'].predict(custom_string_transformed)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.9198396793587175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('queries1.csv')\n",
    "\n",
    "X = df['String']\n",
    "y = df['Class']\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that first transforms your data using TF-IDF and then fits it to a SVC\n",
    "model = make_pipeline(TfidfVectorizer(), SVC(probability=True))\n",
    "\n",
    "# Train your model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate your model using the testing data\n",
    "print(\"Model Accuracy: \", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheese_plate']\n"
     ]
    }
   ],
   "source": [
    "# Your custom string\n",
    "custom_string = \"different cheese\"\n",
    "\n",
    "# Transform your string into a TF-IDF vector\n",
    "custom_string_transformed = model.named_steps['tfidfvectorizer'].transform([custom_string])\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.named_steps['svc'].predict(custom_string_transformed)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the model to a file\n",
    "dump(model, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the model from a file\n",
    "model_2 = load('model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheese_plate']\n"
     ]
    }
   ],
   "source": [
    "# Your custom string\n",
    "custom_string = \"different cheese\"\n",
    "\n",
    "# Transform your string into a TF-IDF vector\n",
    "custom_string_transformed = model_1.named_steps['tfidfvectorizer'].transform([custom_string])\n",
    "\n",
    "# Make prediction\n",
    "prediction = model_1.named_steps['svc'].predict(custom_string_transformed)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pizza\n",
      "dumplings\n",
      "cheese_plate\n",
      "lasagna\n",
      "foie_gras\n"
     ]
    }
   ],
   "source": [
    "# Your custom string\n",
    "custom_string = \"dough cheese and tomato\"\n",
    "\n",
    "# Transform your string into a TF-IDF vector\n",
    "custom_string_transformed = model.named_steps['tfidfvectorizer'].transform([custom_string])\n",
    "\n",
    "# Get probabilities\n",
    "probabilities = model.named_steps['svc'].predict_proba(custom_string_transformed)\n",
    "\n",
    "# Get the indices of the top 5 predictions\n",
    "top5_indices = probabilities[0].argsort()[-5:][::-1]\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = model.named_steps['svc'].classes_\n",
    "\n",
    "# Print the top 5 predicted dishes\n",
    "for i in top5_indices:\n",
    "    print(class_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.4377584584280028,\n",
       "  0.04270574203028125,\n",
       "  0.02681058380264024,\n",
       "  0.019028585013695108,\n",
       "  0.013631286282075097],\n",
       " 0.9999999999999994)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(probabilities[0],reverse=True)[:5],sum(sorted(probabilities[0],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Load the model from a file\n",
    "model_2 = load('model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "croque_madame\n",
      "cheese_plate\n",
      "pizza\n",
      "foie_gras\n",
      "nachos\n"
     ]
    }
   ],
   "source": [
    "# Your custom string\n",
    "custom_string = \"ham and cheese\"\n",
    "\n",
    "# Transform your string into a TF-IDF vector\n",
    "custom_string_transformed = model.named_steps['tfidfvectorizer'].transform([custom_string])\n",
    "\n",
    "# Get probabilities\n",
    "probabilities = model.named_steps['svc'].predict_proba(custom_string_transformed)\n",
    "\n",
    "# Get the indices of the top 5 predictions\n",
    "top5_indices = probabilities[0].argsort()[-5:][::-1]\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = model.named_steps['svc'].classes_\n",
    "\n",
    "# Print the top 5 predicted dishes\n",
    "for i in top5_indices:\n",
    "    print(class_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "croque_madame 0.17546075010608803\n",
      "cheese_plate 0.05577163843944749\n",
      "pizza 0.02578475714521297\n",
      "foie_gras 0.02558948991359066\n",
      "nachos 0.017885596906728963\n"
     ]
    }
   ],
   "source": [
    "probs = sorted(probabilities[0],reverse=True)[:5]\n",
    "for i,idx in enumerate(top5_indices):\n",
    "    print(class_labels[idx],probs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class_list = os.listdir(\"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foie_gras',\n",
       " 'club_sandwich',\n",
       " 'cheese_plate',\n",
       " 'cup_cakes',\n",
       " 'garlic_bread',\n",
       " 'gnocchi',\n",
       " 'ice_cream',\n",
       " 'samosa',\n",
       " 'donuts',\n",
       " 'tuna_tartare',\n",
       " 'filet_mignon',\n",
       " 'seaweed_salad',\n",
       " 'french_toast',\n",
       " 'chicken_curry',\n",
       " 'shrimp_and_grits',\n",
       " 'steak',\n",
       " 'cheesecake',\n",
       " 'red_velvet_cake',\n",
       " 'waffles',\n",
       " 'churros',\n",
       " 'gyoza',\n",
       " 'lobster_roll_sandwich',\n",
       " 'huevos_rancheros',\n",
       " 'breakfast_burrito',\n",
       " 'grilled_cheese_sandwich',\n",
       " 'spaghetti_bolognese',\n",
       " 'falafel',\n",
       " 'poutine',\n",
       " 'greek_salad',\n",
       " 'beef_tartare',\n",
       " 'fried_calamari',\n",
       " 'guacamole',\n",
       " 'ravioli',\n",
       " 'lobster_bisque',\n",
       " 'beet_salad',\n",
       " 'risotto',\n",
       " 'crab_cakes',\n",
       " 'strawberry_shortcake',\n",
       " 'edamame',\n",
       " 'ceviche',\n",
       " 'hot_and_sour_soup',\n",
       " 'spring_rolls',\n",
       " 'sashimi',\n",
       " 'paella',\n",
       " 'clam_chowder',\n",
       " 'miso_soup',\n",
       " 'escargots',\n",
       " 'hot_dog',\n",
       " 'pulled_pork_sandwich',\n",
       " 'bruschetta',\n",
       " 'panna_cotta',\n",
       " 'fish_and_chips',\n",
       " 'pad_thai',\n",
       " 'tiramisu',\n",
       " 'takoyaki',\n",
       " 'macarons',\n",
       " 'apple_pie',\n",
       " 'cannoli',\n",
       " 'scallops',\n",
       " 'frozen_yogurt',\n",
       " 'chicken_quesadilla',\n",
       " 'mussels',\n",
       " 'beef_carpaccio',\n",
       " 'eggs_benedict',\n",
       " 'spaghetti_carbonara',\n",
       " 'omelette',\n",
       " 'sushi',\n",
       " 'chocolate_mousse',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'hummus',\n",
       " 'pork_chop',\n",
       " 'chicken_wings',\n",
       " 'grilled_salmon',\n",
       " 'chocolate_cake',\n",
       " 'tacos',\n",
       " 'hamburger',\n",
       " 'baby_back_ribs',\n",
       " 'pancakes',\n",
       " 'prime_rib',\n",
       " 'pizza',\n",
       " 'nachos',\n",
       " 'macaroni_and_cheese',\n",
       " 'bread_pudding',\n",
       " 'ramen',\n",
       " 'croque_madame',\n",
       " 'lasagna',\n",
       " 'peking_duck',\n",
       " 'deviled_eggs',\n",
       " 'french_fries',\n",
       " 'dumplings',\n",
       " 'fried_rice',\n",
       " 'french_onion_soup',\n",
       " 'pho',\n",
       " 'caprese_salad',\n",
       " 'oysters',\n",
       " 'baklava',\n",
       " 'creme_brulee',\n",
       " 'carrot_cake',\n",
       " 'onion_rings',\n",
       " 'caesar_salad']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "with open('recipes.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "df = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             recipes\n",
      "0  [{'name': 'Foie Gras', 'ingredients': ['Fresh ...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             recipes\n",
      "0  {'name': 'Foie Gras', 'ingredients': ['Fresh d...\n",
      "1  {'name': 'Club Sandwich', 'ingredients': ['Sli...\n",
      "2  {'name': 'Gnocchi', 'ingredients': ['Potatoes'...\n",
      "3  {'name': 'Ice Cream', 'ingredients': ['Heavy c...\n",
      "4  {'name': 'Samosa', 'ingredients': ['Potatoes',...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "with open('recipes.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "# Convert the entire data list into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Foie Gras</td>\n",
       "      <td>[Fresh duck/goose liver, Salt, White pepper, S...</td>\n",
       "      <td>[Remove veins from liver., Season with salt, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Club Sandwich</td>\n",
       "      <td>[Sliced bread, Turkey/Chicken breast, Bacon, L...</td>\n",
       "      <td>[Toast bread., Layer with turkey/chicken, baco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gnocchi</td>\n",
       "      <td>[Potatoes, Flour, Egg, Salt]</td>\n",
       "      <td>[Cook potatoes until tender., Mash and mix wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ice Cream</td>\n",
       "      <td>[Heavy cream, Whole milk, Sugar, Vanilla extra...</td>\n",
       "      <td>[Combine ingredients., Freeze in ice cream mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samosa</td>\n",
       "      <td>[Potatoes, Peas, Spices (such as cumin, corian...</td>\n",
       "      <td>[Boil potatoes., Sauté onion, garlic, ginger, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                        ingredients  \\\n",
       "0      Foie Gras  [Fresh duck/goose liver, Salt, White pepper, S...   \n",
       "1  Club Sandwich  [Sliced bread, Turkey/Chicken breast, Bacon, L...   \n",
       "2        Gnocchi                       [Potatoes, Flour, Egg, Salt]   \n",
       "3      Ice Cream  [Heavy cream, Whole milk, Sugar, Vanilla extra...   \n",
       "4         Samosa  [Potatoes, Peas, Spices (such as cumin, corian...   \n",
       "\n",
       "                                               steps  \n",
       "0  [Remove veins from liver., Season with salt, p...  \n",
       "1  [Toast bread., Layer with turkey/chicken, baco...  \n",
       "2  [Cook potatoes until tender., Mash and mix wit...  \n",
       "3  [Combine ingredients., Freeze in ice cream mak...  \n",
       "4  [Boil potatoes., Sauté onion, garlic, ginger, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply pd.Series to each row to split the dictionary keys into separate columns\n",
    "df_new = df['recipes'].apply(pd.Series)\n",
    "\n",
    "# Print the new DataFrame\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(\"recipes.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Foie Gras</td>\n",
       "      <td>['Fresh duck/goose liver', 'Salt', 'White pepp...</td>\n",
       "      <td>['Remove veins from liver.', 'Season with salt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Club Sandwich</td>\n",
       "      <td>['Sliced bread', 'Turkey/Chicken breast', 'Bac...</td>\n",
       "      <td>['Toast bread.', 'Layer with turkey/chicken, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gnocchi</td>\n",
       "      <td>['Potatoes', 'Flour', 'Egg', 'Salt']</td>\n",
       "      <td>['Cook potatoes until tender.', 'Mash and mix ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ice Cream</td>\n",
       "      <td>['Heavy cream', 'Whole milk', 'Sugar', 'Vanill...</td>\n",
       "      <td>['Combine ingredients.', \"Freeze in ice cream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samosa</td>\n",
       "      <td>['Potatoes', 'Peas', 'Spices (such as cumin, c...</td>\n",
       "      <td>['Boil potatoes.', 'Sauté onion, garlic, ginge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                        ingredients  \\\n",
       "0      Foie Gras  ['Fresh duck/goose liver', 'Salt', 'White pepp...   \n",
       "1  Club Sandwich  ['Sliced bread', 'Turkey/Chicken breast', 'Bac...   \n",
       "2        Gnocchi               ['Potatoes', 'Flour', 'Egg', 'Salt']   \n",
       "3      Ice Cream  ['Heavy cream', 'Whole milk', 'Sugar', 'Vanill...   \n",
       "4         Samosa  ['Potatoes', 'Peas', 'Spices (such as cumin, c...   \n",
       "\n",
       "                                               steps  \n",
       "0  ['Remove veins from liver.', 'Season with salt...  \n",
       "1  ['Toast bread.', 'Layer with turkey/chicken, b...  \n",
       "2  ['Cook potatoes until tender.', 'Mash and mix ...  \n",
       "3  ['Combine ingredients.', \"Freeze in ice cream ...  \n",
       "4  ['Boil potatoes.', 'Sauté onion, garlic, ginge...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"recipes.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Foie Gras\n",
       "1     Club Sandwich\n",
       "2           Gnocchi\n",
       "3         Ice Cream\n",
       "4            Samosa\n",
       "          ...      \n",
       "83          Baklava\n",
       "84     Crème Brûlée\n",
       "85      Carrot Cake\n",
       "86      Onion Rings\n",
       "87     Caesar Salad\n",
       "Name: name, Length: 88, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foie_gras\n"
     ]
    }
   ],
   "source": [
    "# # Read the dishes from the CSV file\n",
    "# df1 = pd.read_csv(\"recipes.csv\")\n",
    "\n",
    "# Create a dictionary mapping dish names to classes\n",
    "dish_to_class = dict(zip(df1['name'], class_list))\n",
    "\n",
    "# Now you can access the class of a dish like this:\n",
    "print(dish_to_class['Foie Gras'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foie_gras',\n",
       " 'club_sandwich',\n",
       " 'cheese_plate',\n",
       " 'cup_cakes',\n",
       " 'garlic_bread',\n",
       " 'gnocchi',\n",
       " 'ice_cream',\n",
       " 'samosa',\n",
       " 'donuts',\n",
       " 'tuna_tartare',\n",
       " 'filet_mignon',\n",
       " 'seaweed_salad',\n",
       " 'french_toast',\n",
       " 'chicken_curry',\n",
       " 'shrimp_and_grits',\n",
       " 'steak',\n",
       " 'cheesecake',\n",
       " 'red_velvet_cake',\n",
       " 'waffles',\n",
       " 'churros',\n",
       " 'gyoza',\n",
       " 'lobster_roll_sandwich',\n",
       " 'huevos_rancheros',\n",
       " 'breakfast_burrito',\n",
       " 'grilled_cheese_sandwich',\n",
       " 'spaghetti_bolognese',\n",
       " 'falafel',\n",
       " 'poutine',\n",
       " 'greek_salad',\n",
       " 'beef_tartare',\n",
       " 'fried_calamari',\n",
       " 'guacamole',\n",
       " 'ravioli',\n",
       " 'lobster_bisque',\n",
       " 'beet_salad',\n",
       " 'risotto',\n",
       " 'crab_cakes',\n",
       " 'strawberry_shortcake',\n",
       " 'edamame',\n",
       " 'ceviche',\n",
       " 'hot_and_sour_soup',\n",
       " 'spring_rolls',\n",
       " 'sashimi',\n",
       " 'paella',\n",
       " 'clam_chowder',\n",
       " 'miso_soup',\n",
       " 'escargots',\n",
       " 'hot_dog',\n",
       " 'pulled_pork_sandwich',\n",
       " 'bruschetta',\n",
       " 'panna_cotta',\n",
       " 'fish_and_chips',\n",
       " 'pad_thai',\n",
       " 'tiramisu',\n",
       " 'takoyaki',\n",
       " 'macarons',\n",
       " 'apple_pie',\n",
       " 'cannoli',\n",
       " 'scallops',\n",
       " 'frozen_yogurt',\n",
       " 'chicken_quesadilla',\n",
       " 'mussels',\n",
       " 'beef_carpaccio',\n",
       " 'eggs_benedict',\n",
       " 'spaghetti_carbonara',\n",
       " 'omelette',\n",
       " 'sushi',\n",
       " 'chocolate_mousse',\n",
       " 'beignets',\n",
       " 'bibimbap',\n",
       " 'hummus',\n",
       " 'pork_chop',\n",
       " 'chicken_wings',\n",
       " 'grilled_salmon',\n",
       " 'chocolate_cake',\n",
       " 'tacos',\n",
       " 'hamburger',\n",
       " 'baby_back_ribs',\n",
       " 'pancakes',\n",
       " 'prime_rib',\n",
       " 'pizza',\n",
       " 'nachos',\n",
       " 'macaroni_and_cheese',\n",
       " 'bread_pudding',\n",
       " 'ramen',\n",
       " 'croque_madame',\n",
       " 'lasagna',\n",
       " 'peking_duck',\n",
       " 'deviled_eggs',\n",
       " 'french_fries',\n",
       " 'dumplings',\n",
       " 'fried_rice',\n",
       " 'french_onion_soup',\n",
       " 'pho',\n",
       " 'caprese_salad',\n",
       " 'oysters',\n",
       " 'baklava',\n",
       " 'creme_brulee',\n",
       " 'carrot_cake',\n",
       " 'onion_rings',\n",
       " 'caesar_salad']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Foie Gras': 'foie_gras',\n",
       " 'Club Sandwich': 'club_sandwich',\n",
       " 'Gnocchi': 'cheese_plate',\n",
       " 'Ice Cream': 'cup_cakes',\n",
       " 'Samosa': 'garlic_bread',\n",
       " 'Donuts': 'gnocchi',\n",
       " 'Tuna Tartare': 'ice_cream',\n",
       " 'Filet Mignon': 'samosa',\n",
       " 'Seaweed Salad': 'donuts',\n",
       " 'French Toast': 'tuna_tartare',\n",
       " 'Chicken Curry': 'filet_mignon',\n",
       " 'Shrimp and Grits': 'seaweed_salad',\n",
       " 'Steak': 'french_toast',\n",
       " 'Cheesecake': 'chicken_curry',\n",
       " 'Red Velvet Cake': 'shrimp_and_grits',\n",
       " 'Waffles': 'steak',\n",
       " 'Churros': 'cheesecake',\n",
       " 'Gyoza': 'red_velvet_cake',\n",
       " 'Lobster Roll Sandwich': 'waffles',\n",
       " 'Huevos Rancheros': 'churros',\n",
       " 'Breakfast Burrito': 'gyoza',\n",
       " 'Grilled Cheese Sandwich': 'lobster_roll_sandwich',\n",
       " 'Spaghetti Bolognese': 'huevos_rancheros',\n",
       " 'Falafel': 'breakfast_burrito',\n",
       " 'Poutine': 'grilled_cheese_sandwich',\n",
       " 'Greek Salad': 'spaghetti_bolognese',\n",
       " 'Beef Tartare': 'falafel',\n",
       " 'Fried Calamari': 'poutine',\n",
       " 'Guacamole': 'greek_salad',\n",
       " 'Ravioli': 'beef_tartare',\n",
       " 'Lobster Bisque': 'fried_calamari',\n",
       " 'Beet Salad': 'guacamole',\n",
       " 'Risotto': 'ravioli',\n",
       " 'Crab Cakes': 'lobster_bisque',\n",
       " 'Strawberry Shortcake': 'beet_salad',\n",
       " 'Edamame': 'risotto',\n",
       " 'Ceviche': 'crab_cakes',\n",
       " 'Hot and Sour Soup': 'strawberry_shortcake',\n",
       " 'Spring Rolls': 'edamame',\n",
       " 'Sashimi': 'ceviche',\n",
       " 'Paella': 'hot_and_sour_soup',\n",
       " 'Clam Chowder': 'spring_rolls',\n",
       " 'Miso Soup': 'sashimi',\n",
       " 'Escargots': 'paella',\n",
       " 'Hot Dog': 'clam_chowder',\n",
       " 'Pulled Pork Sandwich': 'miso_soup',\n",
       " 'Bruschetta': 'escargots',\n",
       " 'Panna Cotta': 'hot_dog',\n",
       " 'Fish and Chips': 'pulled_pork_sandwich',\n",
       " 'Pad Thai': 'bruschetta',\n",
       " 'Tiramisu': 'panna_cotta',\n",
       " 'Takoyaki': 'fish_and_chips',\n",
       " 'Macarons': 'pad_thai',\n",
       " 'Apple Pie': 'tiramisu',\n",
       " 'Cannoli': 'takoyaki',\n",
       " 'Scallops': 'macarons',\n",
       " 'Frozen Yogurt': 'apple_pie',\n",
       " 'Chicken Quesadilla': 'cannoli',\n",
       " 'Mussels': 'scallops',\n",
       " 'Beef Carpaccio': 'frozen_yogurt',\n",
       " 'Eggs Benedict': 'chicken_quesadilla',\n",
       " 'Spaghetti Carbonara': 'mussels',\n",
       " 'Omelette': 'beef_carpaccio',\n",
       " 'Sushi': 'eggs_benedict',\n",
       " 'Chocolate Mousse': 'spaghetti_carbonara',\n",
       " 'Beignets': 'omelette',\n",
       " 'Bibimbap': 'sushi',\n",
       " 'Hummus': 'chocolate_mousse',\n",
       " 'Pork Chop': 'beignets',\n",
       " 'Chicken Wings': 'bibimbap',\n",
       " 'Grilled Salmon': 'hummus',\n",
       " 'Chocolate Cake': 'pork_chop',\n",
       " 'Tacos': 'chicken_wings',\n",
       " 'Hamburger': 'grilled_salmon',\n",
       " 'Baby Back Ribs': 'chocolate_cake',\n",
       " 'Deviled Eggs': 'tacos',\n",
       " 'French Fries': 'hamburger',\n",
       " 'Dumplings': 'baby_back_ribs',\n",
       " 'Fried Rice': 'pancakes',\n",
       " 'French Onion Soup': 'prime_rib',\n",
       " 'Pho': 'pizza',\n",
       " 'Caprese Salad': 'nachos',\n",
       " 'Oysters': 'macaroni_and_cheese',\n",
       " 'Baklava': 'bread_pudding',\n",
       " 'Crème Brûlée': 'ramen',\n",
       " 'Carrot Cake': 'croque_madame',\n",
       " 'Onion Rings': 'lasagna',\n",
       " 'Caesar Salad': 'peking_duck'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dish_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foie_gras.ingredients</th>\n",
       "      <th>foie_gras.recipe</th>\n",
       "      <th>club_sandwich.ingredients</th>\n",
       "      <th>club_sandwich.recipe</th>\n",
       "      <th>cheese_plate.ingredients</th>\n",
       "      <th>cheese_plate.recipe</th>\n",
       "      <th>cup_cakes.ingredients</th>\n",
       "      <th>cup_cakes.recipe</th>\n",
       "      <th>garlic_bread.ingredients</th>\n",
       "      <th>garlic_bread.recipe</th>\n",
       "      <th>gnocchi.ingredients</th>\n",
       "      <th>gnocchi.recipe</th>\n",
       "      <th>ice_cream.ingredients</th>\n",
       "      <th>ice_cream.recipe</th>\n",
       "      <th>samosa.ingredients</th>\n",
       "      <th>samosa.recipe</th>\n",
       "      <th>donuts.ingredients</th>\n",
       "      <th>donuts.recipe</th>\n",
       "      <th>tuna_tartare.ingredients</th>\n",
       "      <th>tuna_tartare.recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1 whole fresh duck or goose liver, Salt, Pepp...</td>\n",
       "      <td>1. Remove any veins or membranes from the live...</td>\n",
       "      <td>[Sliced bread, Turkey or chicken breast, Bacon...</td>\n",
       "      <td>1. Toast three slices of bread. 2. Cook bacon ...</td>\n",
       "      <td>[Assorted cheeses (such as brie, cheddar, goud...</td>\n",
       "      <td>1. Arrange the assorted cheeses on a serving p...</td>\n",
       "      <td>[All-purpose flour, Sugar, Baking powder, Salt...</td>\n",
       "      <td>1. Preheat oven to 350°F (175°C). Line a muffi...</td>\n",
       "      <td>[French bread or baguette, Butter, Garlic clov...</td>\n",
       "      <td>1. Preheat oven to 375°F (190°C). 2. Slice the...</td>\n",
       "      <td>[Potatoes, Flour, Egg, Salt]</td>\n",
       "      <td>1. Boil potatoes until tender, then peel and m...</td>\n",
       "      <td>[Heavy cream, Whole milk, Sugar, Vanilla extract]</td>\n",
       "      <td>1. In a bowl, whisk together heavy cream, whol...</td>\n",
       "      <td>[Potatoes, Peas, Carrots, Onion, Garlic, Ginge...</td>\n",
       "      <td>1. Boil potatoes until tender, then peel and m...</td>\n",
       "      <td>[All-purpose flour, Sugar, Yeast, Milk, Egg, B...</td>\n",
       "      <td>1. In a bowl, combine flour, sugar, yeast, and...</td>\n",
       "      <td>[Sushi-grade tuna, Soy sauce, Sesame oil, Lime...</td>\n",
       "      <td>1. Dice sushi-grade tuna into small cubes. 2. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               foie_gras.ingredients  \\\n",
       "0  [1 whole fresh duck or goose liver, Salt, Pepp...   \n",
       "\n",
       "                                    foie_gras.recipe  \\\n",
       "0  1. Remove any veins or membranes from the live...   \n",
       "\n",
       "                           club_sandwich.ingredients  \\\n",
       "0  [Sliced bread, Turkey or chicken breast, Bacon...   \n",
       "\n",
       "                                club_sandwich.recipe  \\\n",
       "0  1. Toast three slices of bread. 2. Cook bacon ...   \n",
       "\n",
       "                            cheese_plate.ingredients  \\\n",
       "0  [Assorted cheeses (such as brie, cheddar, goud...   \n",
       "\n",
       "                                 cheese_plate.recipe  \\\n",
       "0  1. Arrange the assorted cheeses on a serving p...   \n",
       "\n",
       "                               cup_cakes.ingredients  \\\n",
       "0  [All-purpose flour, Sugar, Baking powder, Salt...   \n",
       "\n",
       "                                    cup_cakes.recipe  \\\n",
       "0  1. Preheat oven to 350°F (175°C). Line a muffi...   \n",
       "\n",
       "                            garlic_bread.ingredients  \\\n",
       "0  [French bread or baguette, Butter, Garlic clov...   \n",
       "\n",
       "                                 garlic_bread.recipe  \\\n",
       "0  1. Preheat oven to 375°F (190°C). 2. Slice the...   \n",
       "\n",
       "            gnocchi.ingredients  \\\n",
       "0  [Potatoes, Flour, Egg, Salt]   \n",
       "\n",
       "                                      gnocchi.recipe  \\\n",
       "0  1. Boil potatoes until tender, then peel and m...   \n",
       "\n",
       "                               ice_cream.ingredients  \\\n",
       "0  [Heavy cream, Whole milk, Sugar, Vanilla extract]   \n",
       "\n",
       "                                    ice_cream.recipe  \\\n",
       "0  1. In a bowl, whisk together heavy cream, whol...   \n",
       "\n",
       "                                  samosa.ingredients  \\\n",
       "0  [Potatoes, Peas, Carrots, Onion, Garlic, Ginge...   \n",
       "\n",
       "                                       samosa.recipe  \\\n",
       "0  1. Boil potatoes until tender, then peel and m...   \n",
       "\n",
       "                                  donuts.ingredients  \\\n",
       "0  [All-purpose flour, Sugar, Yeast, Milk, Egg, B...   \n",
       "\n",
       "                                       donuts.recipe  \\\n",
       "0  1. In a bowl, combine flour, sugar, yeast, and...   \n",
       "\n",
       "                            tuna_tartare.ingredients  \\\n",
       "0  [Sushi-grade tuna, Soy sauce, Sesame oil, Lime...   \n",
       "\n",
       "                                 tuna_tartare.recipe  \n",
       "0  1. Dice sushi-grade tuna into small cubes. 2. ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "with open('recipes1.yaml', 'r') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
