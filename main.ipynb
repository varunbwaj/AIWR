{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import tensorflow as tf\n",
    "from helper_functions import *\n",
    "import pandas as pd\n",
    "importTensorflow(memory=4090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>String</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rich and buttery delicacy recipes</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luxurious appetizer with duck liver</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indulgent gourmet dish preparation</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recipes for savory liver pâté</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delicate and decadent French cuisine ideas</td>\n",
       "      <td>foie_gras</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       String      Class\n",
       "0           Rich and buttery delicacy recipes  foie_gras\n",
       "1         Luxurious appetizer with duck liver  foie_gras\n",
       "2          Indulgent gourmet dish preparation  foie_gras\n",
       "3               Recipes for savory liver pâté  foie_gras\n",
       "4  Delicate and decadent French cuisine ideas  foie_gras"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"queries.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = set()\n",
    "counter = -1\n",
    "l = []\n",
    "for thing in df.Class:\n",
    "    if thing in d:\n",
    "      l.append(counter)\n",
    "    else:\n",
    "        counter += 1\n",
    "        d.add(thing)\n",
    "        l.append(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = list(set(df.Class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classEncode'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>String</th>\n",
       "      <th>Class</th>\n",
       "      <th>classEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rich and buttery delicacy recipes</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luxurious appetizer with duck liver</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Indulgent gourmet dish preparation</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recipes for savory liver pâté</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delicate and decadent French cuisine ideas</td>\n",
       "      <td>foie_gras</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       String      Class  classEncode\n",
       "0           Rich and buttery delicacy recipes  foie_gras            0\n",
       "1         Luxurious appetizer with duck liver  foie_gras            0\n",
       "2          Indulgent gourmet dish preparation  foie_gras            0\n",
       "3               Recipes for savory liver pâté  foie_gras            0\n",
       "4  Delicate and decadent French cuisine ideas  foie_gras            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>String</th>\n",
       "      <th>Class</th>\n",
       "      <th>classEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>Meals featuring homemade classic pho</td>\n",
       "      <td>pho</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>Cooking tutorials for searing pork chops to pe...</td>\n",
       "      <td>pork_chop</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>Homemade dessert with a luxurious and indulgen...</td>\n",
       "      <td>creme_brulee</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Savory starter with fresh ingredients and zest...</td>\n",
       "      <td>beef_tartare</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>Recipes for lasagna with a sprinkle of Parmesa...</td>\n",
       "      <td>lasagna</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 String         Class  \\\n",
       "2309               Meals featuring homemade classic pho           pho   \n",
       "1773  Cooking tutorials for searing pork chops to pe...     pork_chop   \n",
       "2399  Homemade dessert with a luxurious and indulgen...  creme_brulee   \n",
       "723   Savory starter with fresh ingredients and zest...  beef_tartare   \n",
       "2130  Recipes for lasagna with a sprinkle of Parmesa...       lasagna   \n",
       "\n",
       "      classEncode  \n",
       "2309           93  \n",
       "1773           71  \n",
       "2399           97  \n",
       "723            29  \n",
       "2130           86  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.String, df.classEncode, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1984, 496)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 11,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 13,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 12,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 12,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 12,\n",
       " 9,\n",
       " 11,\n",
       " 6,\n",
       " 7,\n",
       " 11,\n",
       " 9,\n",
       " 10,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 13,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 12,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 13,\n",
       " 11,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 12,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 12,\n",
       " 8,\n",
       " 8,\n",
       " 12,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 11,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 12,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 7,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 11,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 11,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 11,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 12,\n",
       " 9,\n",
       " 11,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 13,\n",
       " 12,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 10,\n",
       " 6,\n",
       " 13,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 12,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 11,\n",
       " 7,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 12,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 11,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 12,\n",
       " 6,\n",
       " 8,\n",
       " 11,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 12,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 5,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 12,\n",
       " 6,\n",
       " 7,\n",
       " 11,\n",
       " 10,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 12,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 12,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 13,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 13,\n",
       " 11,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 13,\n",
       " 7,\n",
       " 10,\n",
       " 5,\n",
       " 12,\n",
       " 10,\n",
       " 7,\n",
       " 5,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 6,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 11,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 15,\n",
       " 10,\n",
       " 7,\n",
       " 12,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 11,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 12,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 13,\n",
       " 7,\n",
       " 7,\n",
       " 12,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 11,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 11,\n",
       " 11,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 11,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 11,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 11,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 11,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 13,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 14,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 12,\n",
       " 7,\n",
       " 10,\n",
       " 14,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 12,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 13,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 13,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 12,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 11,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 12,\n",
       " 7,\n",
       " 12,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 12,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 13,\n",
       " 11,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 11,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 10,\n",
       " 6,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 12,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 12,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 7,\n",
       " 11,\n",
       " 7,\n",
       " 13,\n",
       " 10,\n",
       " 13,\n",
       " 7,\n",
       " 10,\n",
       " 11,\n",
       " 8,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 11,\n",
       " 7,\n",
       " 12,\n",
       " 10,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 12,\n",
       " 8,\n",
       " 8,\n",
       " 12,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 12,\n",
       " 8,\n",
       " 8,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 13,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 10,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 10,\n",
       " 6,\n",
       " 10,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 10,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length = 25000\n",
    "max_length = [len(i.split()) for i in df.String]\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_length = int(np.percentile(max_length, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorization\n",
    "text_vector = tf.keras.layers.TextVectorization(max_tokens=vocab_length,\n",
    "                                                output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector.adapt(df.String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'for', 'with', 'and']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12), dtype=int64, numpy=\n",
       "array([[ 199, 1126,    2,  151,  382,    0,    0,    0,    0,    0,    0,\n",
       "           0]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector([\"Luxurious ingredient for gourmet dining\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "embedding = tf.keras.layers.Embedding(input_dim = vocab_length,\n",
    "                                      input_length=max_length,\n",
    "                                      output_dim=1024,\n",
    "                                      mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embedding(text_vector([\"Luxurious ingredient for gourmet dining\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12, 1024), dtype=float32, numpy=\n",
       "array([[[ 0.04043684,  0.04742959, -0.02143621, ...,  0.04339835,\n",
       "         -0.00970022,  0.04381562],\n",
       "        [-0.00509573,  0.00864817,  0.02083527, ...,  0.01732795,\n",
       "         -0.04011247, -0.01027735],\n",
       "        [ 0.04611878,  0.01603084, -0.02062531, ..., -0.04476657,\n",
       "          0.04253707,  0.0163291 ],\n",
       "        ...,\n",
       "        [ 0.01093497, -0.02421271,  0.04809925, ..., -0.04501803,\n",
       "         -0.0125985 , -0.03588951],\n",
       "        [ 0.01093497, -0.02421271,  0.04809925, ..., -0.04501803,\n",
       "         -0.0125985 , -0.03588951],\n",
       "        [ 0.01093497, -0.02421271,  0.04809925, ..., -0.04501803,\n",
       "         -0.0125985 , -0.03588951]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_train = tf.one_hot(y_train, depth=101)\n",
    "one_hot_encoded_test = tf.one_hot(y_test, depth=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_one_hot = tf.data.Dataset.from_tensor_slices((X_train, one_hot_encoded_train)).shuffle(1000).batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "test_data_one_hot = tf.data.Dataset.from_tensor_slices((X_test, one_hot_encoded_test)).batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 12)                0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 12, 1024)          25600000  \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 12, 1024)          4724736   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 128)               443136    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 101)               13029     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30797925 (117.48 MB)\n",
      "Trainable params: 30797669 (117.48 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# conv1d\n",
    "inputs = tf.keras.layers.Input(shape=(1, ), dtype='string')\n",
    "x = text_vector(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(512, return_sequences=True))(x)\n",
    "# x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(x)\n",
    "# x = tf.keras.layers.Conv1D(256, kernel_size=3)(x)\n",
    "# x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.GRU(128)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(len(class_list), activation='softmax')(x)\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch : 3e-3/(1+epoch)**(2))\n",
    "\n",
    "model = tf.keras.models.Model(inputs, outputs)\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 12s 148ms/step - loss: 2.6294 - accuracy: 0.4808 - val_loss: 3.6414 - val_accuracy: 0.5547 - lr: 0.0030\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 2s 47ms/step - loss: 0.6037 - accuracy: 0.9017 - val_loss: 3.1365 - val_accuracy: 0.6719 - lr: 7.5000e-04\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.3095 - accuracy: 0.9567 - val_loss: 2.8524 - val_accuracy: 0.6797 - lr: 3.3333e-04\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.2451 - accuracy: 0.9753 - val_loss: 2.6154 - val_accuracy: 0.6797 - lr: 1.8750e-04\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 1s 31ms/step - loss: 0.2049 - accuracy: 0.9803 - val_loss: 2.3894 - val_accuracy: 0.6797 - lr: 1.2000e-04\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 1s 32ms/step - loss: 0.1884 - accuracy: 0.9814 - val_loss: 2.1879 - val_accuracy: 0.6875 - lr: 8.3333e-05\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 1s 25ms/step - loss: 0.1747 - accuracy: 0.9834 - val_loss: 2.0110 - val_accuracy: 0.6875 - lr: 6.1224e-05\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 1s 23ms/step - loss: 0.1672 - accuracy: 0.9844 - val_loss: 1.8637 - val_accuracy: 0.6953 - lr: 4.6875e-05\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 1s 28ms/step - loss: 0.1638 - accuracy: 0.9829 - val_loss: 1.7468 - val_accuracy: 0.7031 - lr: 3.7037e-05\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 1s 29ms/step - loss: 0.1537 - accuracy: 0.9884 - val_loss: 1.6635 - val_accuracy: 0.7031 - lr: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data_one_hot,\n",
    "                    epochs=10,\n",
    "                    validation_data=(test_data_one_hot),\n",
    "                    validation_steps=int(0.25*len(test_data_one_hot)),\n",
    "                    steps_per_epoch=len(train_data_one_hot),\n",
    "                    callbacks=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 1.6710 - accuracy: 0.6875"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 1.5141 - accuracy: 0.7238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5141034126281738, 0.7237903475761414]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 75_3_gru_one_hot/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 75_3_gru_one_hot/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"75_3_gru_one_hot/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([55])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(model.predict([\"Cooking tutorials for achieving the perfect macaron feet\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tuna_tartare'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list[55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/frameworks/TensorFlow2/variations/universal-sentence-encoder/versions/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=float32, numpy=\n",
       "array([[-0.02827955,  0.04139925,  0.0158745 ,  0.04136196,  0.05827901,\n",
       "         0.03923946, -0.02325298,  0.00041435, -0.0523848 ,  0.05865195,\n",
       "        -0.02272667, -0.06025485, -0.06244032, -0.04705139, -0.0854217 ,\n",
       "         0.02652335, -0.01217343, -0.06420659,  0.00995875, -0.04074476,\n",
       "         0.04196679,  0.07901078, -0.01970854, -0.01796671,  0.04481786,\n",
       "         0.05687874, -0.04481113,  0.02043473, -0.07764187, -0.03506602,\n",
       "         0.04480224,  0.06017666, -0.06590992, -0.00959308, -0.06850488,\n",
       "         0.01169699, -0.01823763, -0.04149666,  0.04416808, -0.00070136,\n",
       "         0.02090705, -0.01576048,  0.08526254, -0.06790678, -0.08336893,\n",
       "         0.05019844, -0.00493785, -0.0217003 , -0.06885814, -0.08142836,\n",
       "        -0.01130935,  0.05944003,  0.0343403 , -0.024447  ,  0.02204055,\n",
       "         0.00451931, -0.0093224 ,  0.00847749,  0.07504914, -0.01754982,\n",
       "        -0.01578058, -0.0539532 , -0.0403356 ,  0.03714855,  0.00210826,\n",
       "        -0.00024727,  0.01853372, -0.01555387,  0.04902043,  0.0215243 ,\n",
       "        -0.00883739, -0.00132317,  0.0632694 , -0.05033035,  0.0133791 ,\n",
       "         0.07217039,  0.03619527,  0.05288543,  0.00489042, -0.00152252,\n",
       "        -0.02639268,  0.02710364, -0.07722323,  0.05245246,  0.0084131 ,\n",
       "         0.06158551, -0.00873609, -0.01346122,  0.03535343,  0.06682745,\n",
       "        -0.05061421, -0.02802181, -0.05640054,  0.07549605,  0.08515239,\n",
       "         0.03598386, -0.01613945, -0.05361476, -0.06483606,  0.03645802,\n",
       "        -0.01118209, -0.01816041, -0.04102491,  0.07335271, -0.02652142,\n",
       "        -0.01230943,  0.05611953, -0.01783764, -0.04163697,  0.05616749,\n",
       "        -0.04432684,  0.04278602, -0.0396465 ,  0.0646119 , -0.01045007,\n",
       "         0.05492768, -0.06764   , -0.01854295, -0.03633895, -0.02281415,\n",
       "        -0.01557597, -0.05297634,  0.07999694,  0.01159692, -0.07239021,\n",
       "         0.04662675,  0.05261846,  0.04011691, -0.00180796, -0.03024258,\n",
       "        -0.01528361,  0.08469459, -0.02149477,  0.03287111,  0.02712416,\n",
       "         0.01922004,  0.06587785, -0.05047048,  0.05546333, -0.04056524,\n",
       "         0.02383948, -0.07270185,  0.04102707, -0.03434009,  0.00383469,\n",
       "         0.0525368 , -0.06805466, -0.05281138, -0.03326262, -0.03837705,\n",
       "        -0.02571854, -0.00359338, -0.01698922, -0.00411873, -0.00466781,\n",
       "        -0.03299821,  0.0776506 , -0.08127064,  0.06711341,  0.04045724,\n",
       "         0.02872503, -0.06388379,  0.00210871,  0.00782175, -0.03458039,\n",
       "        -0.02044715, -0.01159336,  0.07396039,  0.00965847, -0.02694934,\n",
       "         0.04493788, -0.02246086, -0.00786459, -0.06007979,  0.02178246,\n",
       "        -0.05759607,  0.00763241, -0.03117277, -0.02746996, -0.05718815,\n",
       "        -0.02543234,  0.05905129,  0.00236   , -0.00794248,  0.06688178,\n",
       "        -0.07940121, -0.08012855,  0.02794292, -0.06491015,  0.01532169,\n",
       "        -0.05273021, -0.01182821,  0.06811851, -0.02241367, -0.08080123,\n",
       "         0.0029826 ,  0.04765894, -0.06494225,  0.05236627,  0.04306743,\n",
       "        -0.01337252,  0.05062761,  0.04597378, -0.00895405, -0.05503559,\n",
       "         0.01067308,  0.03094991, -0.05833574, -0.01188043, -0.02198731,\n",
       "        -0.03099309, -0.04268731, -0.03613679,  0.04853871, -0.04326802,\n",
       "         0.04409991,  0.01268635,  0.00188456,  0.06866593, -0.01248383,\n",
       "        -0.06486963, -0.04978572, -0.0642212 ,  0.03583671,  0.01848689,\n",
       "        -0.0632621 , -0.03406971, -0.0643414 ,  0.03515489, -0.0850099 ,\n",
       "        -0.00333244, -0.00204846,  0.01882225,  0.05401105,  0.0407843 ,\n",
       "        -0.03839431,  0.03415786,  0.04176439, -0.03731776,  0.04152343,\n",
       "         0.03698787, -0.03763819,  0.06286954, -0.06256777, -0.00719011,\n",
       "        -0.03765377,  0.08542155, -0.04744418, -0.0056617 , -0.03222129,\n",
       "         0.0483229 ,  0.01636825, -0.04898892, -0.03835526, -0.03273488,\n",
       "         0.05897441,  0.0770193 , -0.05776113,  0.05681945, -0.05408887,\n",
       "        -0.05216267, -0.00351647,  0.02658603,  0.03230743,  0.05244872,\n",
       "        -0.04422412, -0.0719557 ,  0.05955521,  0.00670999,  0.05815773,\n",
       "         0.00483626, -0.06503953,  0.08405782, -0.02965264,  0.06922042,\n",
       "         0.01645097, -0.02464926,  0.04732374,  0.07647896,  0.04424129,\n",
       "        -0.04727251, -0.06129421, -0.01560491, -0.04604938,  0.04956502,\n",
       "         0.01295524, -0.00407629, -0.05784734, -0.08075306, -0.07211418,\n",
       "         0.03917404, -0.0104049 ,  0.08501976, -0.00768787,  0.03773287,\n",
       "         0.06043247, -0.01555819,  0.06381503, -0.0829386 ,  0.01684546,\n",
       "        -0.07806526, -0.05536098,  0.03612512, -0.03079045, -0.04450752,\n",
       "         0.06703198, -0.01276224, -0.0367284 , -0.03833761,  0.01622674,\n",
       "         0.02054748,  0.00815744,  0.03425827,  0.07169329, -0.02483868,\n",
       "        -0.04708996, -0.0442684 ,  0.03970777, -0.03052518, -0.01383029,\n",
       "        -0.06781227, -0.03911768,  0.03275026,  0.0854122 , -0.05237104,\n",
       "         0.067903  , -0.05391993, -0.00545174,  0.0152669 ,  0.02606796,\n",
       "        -0.02094297, -0.0657393 ,  0.04507609,  0.01791511,  0.03173437,\n",
       "        -0.08541661,  0.05419872, -0.04671007,  0.04154746, -0.07136454,\n",
       "         0.03114983, -0.05634807,  0.07588852,  0.03239295,  0.03951059,\n",
       "        -0.0854217 ,  0.03392735, -0.0159019 , -0.06784264,  0.01044554,\n",
       "        -0.00817643, -0.00361952,  0.06391355, -0.04922442,  0.01609226,\n",
       "         0.02015486, -0.07657234,  0.05772162, -0.02609039, -0.00987043,\n",
       "        -0.05046903, -0.0764938 ,  0.01486647,  0.0581895 , -0.04087284,\n",
       "         0.04418414,  0.07927781, -0.01446746, -0.03690535,  0.02986745,\n",
       "        -0.00091733,  0.01189726,  0.03802148, -0.06592464, -0.01606449,\n",
       "         0.0066907 , -0.0057257 ,  0.00098787, -0.05775713,  0.03046099,\n",
       "        -0.05262164,  0.00268357,  0.03192945, -0.00181159, -0.0124534 ,\n",
       "         0.04135694, -0.00514624,  0.01013115, -0.01195709,  0.06192394,\n",
       "        -0.02283589, -0.05232076, -0.0563994 ,  0.00125278,  0.01709221,\n",
       "        -0.04619158, -0.01268748,  0.01403596, -0.04108427, -0.04655584,\n",
       "        -0.02383129,  0.02632782,  0.00547972, -0.00288855, -0.0130329 ,\n",
       "         0.01029116, -0.0558189 , -0.01265709, -0.02512836, -0.00228295,\n",
       "        -0.01889152,  0.04244555, -0.05902863, -0.0541469 ,  0.03148131,\n",
       "         0.02098725,  0.06246495,  0.07173882,  0.01255771, -0.03040699,\n",
       "        -0.00882935,  0.04649293,  0.01303933,  0.06465471,  0.0306766 ,\n",
       "        -0.027249  , -0.01239839,  0.04121556, -0.02216457, -0.04085838,\n",
       "         0.0042977 ,  0.04470726, -0.0223027 ,  0.0061038 , -0.03139653,\n",
       "        -0.05635395, -0.01642301, -0.04565569,  0.05823489, -0.04306548,\n",
       "        -0.02401965, -0.04084153,  0.00990211, -0.07105294,  0.02248328,\n",
       "         0.04891014,  0.01060291, -0.02613125,  0.04073182,  0.00361549,\n",
       "         0.02832721,  0.00689403,  0.00326136, -0.05357255, -0.02289994,\n",
       "         0.01777013, -0.08260524,  0.00943824, -0.01300635,  0.00973949,\n",
       "         0.0437028 ,  0.04386302,  0.07644837, -0.06348479,  0.01686282,\n",
       "        -0.04210082, -0.04305721,  0.02059633,  0.04631615, -0.00867668,\n",
       "        -0.04045266,  0.02605329,  0.0444999 ,  0.01955211, -0.04256656,\n",
       "        -0.0650665 ,  0.01189553, -0.05653929,  0.05237111, -0.00389865,\n",
       "         0.072102  ,  0.01417672, -0.02464504,  0.03463396,  0.04692737,\n",
       "        -0.01212256, -0.02089501,  0.01725075, -0.0854217 , -0.05940509,\n",
       "         0.00787838,  0.03148341,  0.01626406,  0.01833644,  0.00879132,\n",
       "        -0.07590401, -0.0285025 , -0.05386396,  0.01819162, -0.05297362,\n",
       "        -0.00987213, -0.07611449,  0.0402532 , -0.06227576, -0.04672966,\n",
       "         0.07004995, -0.07759   , -0.02254889, -0.03443693, -0.0047511 ,\n",
       "        -0.02098977, -0.08200608]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed([\"Rice cooked food\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder_layer = hub.KerasLayer(embed,\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.models.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    # tf.keras.layers.Conv1D(64, kernel_size=2),\n",
    "    # tf.keras.layers.GlobalAveragePooling1D,\n",
    "    # tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_list), activation='softmax')\n",
    "])\n",
    "model_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 101)               51813     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256849637 (979.80 MB)\n",
      "Trainable params: 51813 (202.39 KB)\n",
      "Non-trainable params: 256797824 (979.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31/31 [==============================] - 1s 15ms/step - loss: 4.5208 - accuracy: 0.1371 - val_loss: 4.3975 - val_accuracy: 0.2500\n",
      "Epoch 2/5\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.2335 - accuracy: 0.5615 - val_loss: 4.1786 - val_accuracy: 0.3906\n",
      "Epoch 3/5\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 3.9766 - accuracy: 0.6820 - val_loss: 3.9832 - val_accuracy: 0.4688\n",
      "Epoch 4/5\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 3.7297 - accuracy: 0.7283 - val_loss: 3.7664 - val_accuracy: 0.4844\n",
      "Epoch 5/5\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 3.4942 - accuracy: 0.7656 - val_loss: 3.5908 - val_accuracy: 0.5156\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(train_data_one_hot,\n",
    "                    epochs=5,\n",
    "                    validation_data=(test_data_one_hot),\n",
    "                    validation_steps=int(0.2*len(test_data_one_hot)),\n",
    "                    steps_per_epoch=len(train_data_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 3.5908 - accuracy: 0.5156"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 3.6407 - accuracy: 0.5746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.640739679336548, 0.5745967626571655]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(test_data_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
